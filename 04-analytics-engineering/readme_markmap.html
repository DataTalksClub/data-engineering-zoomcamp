<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://unpkg.com/@highlightjs/cdn-assets@11.8.0/styles/default.min.css"><link rel="stylesheet" href="https://unpkg.com/markmap-toolbar@0.15.6/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://unpkg.com/d3@7.8.5/dist/d3.min.js"></script><script src="https://unpkg.com/markmap-view@0.15.6/dist/browser/index.js"></script><script src="https://unpkg.com/markmap-toolbar@0.15.6/dist/index.js"></script><script>(r => {
                setTimeout(r);
              })(() => {
  const {
    markmap,
    mm
  } = window;
  const {
    el
  } = markmap.Toolbar.create(mm);
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root2, jsonOptions) => {
                const markmap = getMarkmap();
                window.mm = markmap.Markmap.create(
                  "svg#mindmap",
                  (getOptions || markmap.deriveOptions)(jsonOptions),
                  root2
                );
              })(() => window.markmap,null,{"type":"heading","depth":0,"payload":{"lines":[0,1]},"content":"Week 4: Analytics Engineering","children":[{"type":"heading","depth":1,"payload":{"lines":[3,4]},"content":"Prerequisites","children":[{"type":"bullet_list","depth":2,"payload":{"lines":[6,13]},"content":"","children":[{"type":"list_item","depth":3,"payload":{"lines":[6,7]},"content":"A running warehouse (BigQuery or postgres)","children":[]},{"type":"list_item","depth":3,"payload":{"lines":[7,8]},"content":"A set of running pipelines ingesting the project dataset (week 3 completed)","children":[]},{"type":"list_item","depth":3,"payload":{"lines":[8,9]},"content":"The following datasets ingested from the course <a href=\"https://github.com/DataTalksClub/nyc-tlc-data/\">Datasets list</a>:","children":[{"type":"list_item","depth":4,"payload":{"lines":[9,10]},"content":"Yellow taxi data - Years 2019 and 2020","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[10,11]},"content":"Green taxi data - Years 2019 and 2020","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[11,12]},"content":"fhv data - Year 2019.","children":[]}]}]},{"type":"blockquote","depth":2,"payload":{"lines":[13,17]},"content":"","children":[{"type":"paragraph","depth":3,"payload":{"lines":[13,14]},"content":"[!NOTE]","children":[]},{"type":"bullet_list","depth":3,"payload":{"lines":[14,17]},"content":"","children":[{"type":"list_item","depth":4,"payload":{"lines":[14,15]},"content":"We have two quick hack to load that data quicker, follow <a href=\"https://www.youtube.com/watch?v=Mork172sK_c&amp;list=PLaNLNpjZpzwgneiI-Gl8df8GCsPYp_6Bs\">this video</a> for option 1 or check instructions in <a href=\"../03-data-warehouse/extras\">week3/extras</a> for option 2","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[15,16]},"content":"option 1 being ingesting from GCP BigQuery public datasets of nyc taxi data","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[16,17]},"content":"option 2 is the <code>web_to_gcs</code> script - see notes below on my preferences","children":[]}]}]}]},{"type":"heading","depth":1,"payload":{"lines":[18,19]},"content":"Setting up your environment","children":[{"type":"blockquote","depth":2,"payload":{"lines":[20,24]},"content":"","children":[{"type":"paragraph","depth":3,"payload":{"lines":[20,22]},"content":"[!NOTE]<br>\nthe <em>cloud</em> setup is the preferred option.","children":[]},{"type":"paragraph","depth":3,"payload":{"lines":[23,24]},"content":"the <em>local</em> setup does not require a cloud database.","children":[]}]},{"type":"table","depth":2,"payload":{"lines":[25,33]},"content":"","children":[{"type":"thead","depth":3,"payload":{"lines":[25,26]},"content":"","children":[{"type":"th","depth":4,"payload":{"lines":[25,26]},"content":"Alternative A","children":[]},{"type":"th","depth":4,"payload":{"lines":[25,26]},"content":"Alternative B","children":[]}]},{"type":"tbody","depth":3,"payload":{"lines":[27,33]},"content":"","children":[{"type":"tr","depth":4,"payload":{},"content":"","children":[{"type":"td","depth":5,"payload":{},"content":"Setting up dbt for using BigQuery (cloud)","children":[]},{"type":"td","depth":5,"payload":{},"content":"Setting up dbt for using Postgres locally","children":[]}]},{"type":"tr","depth":4,"payload":{},"content":"","children":[{"type":"td","depth":5,"payload":{},"content":"- Open a free developer dbt cloud account following <a href=\"https://www.getdbt.com/signup/\">this link</a>","children":[]},{"type":"td","depth":5,"payload":{},"content":"- Open a free developer dbt cloud account following <a href=\"https://www.getdbt.com/signup/\">this link</a><br><br>","children":[]}]},{"type":"tr","depth":4,"payload":{},"content":"","children":[{"type":"td","depth":5,"payload":{},"content":"- <a href=\"[https://docs.getdbt.com/docs/dbt-cloud/cloud-configuring-dbt-cloud/cloud-setting-up-bigquery-oauth](https://docs.getdbt.com/guides/bigquery?step=4)\">Following these instructions to connect to your BigQuery instance</a>","children":[]},{"type":"td","depth":5,"payload":{},"content":"- follow the <a href=\"[https://docs.getdbt.com/dbt-cli/installation](https://docs.getdbt.com/docs/core/installation-overview)\">official dbt documentation</a> or <br>- follow the <a href=\"docker_setup/README.md\">dbt core with BigQuery on Docker</a> guide to setup dbt locally on docker or <br>- use a docker image from oficial <a href=\"https://docs.getdbt.com/docs/core/docker-install\">Install with Docker</a>.","children":[]}]},{"type":"tr","depth":4,"payload":{},"content":"","children":[{"type":"td","depth":5,"payload":{},"content":"- More detailed instructions in <a href=\"dbt_cloud_setup.md\">dbt_cloud_setup.md</a>","children":[]},{"type":"td","depth":5,"payload":{},"content":"- You will need to install the latest version with the BigQuery adapter (dbt-bigquery).","children":[]}]},{"type":"tr","depth":4,"payload":{},"content":"","children":[{"type":"td","depth":5,"payload":{},"content":"","children":[]},{"type":"td","depth":5,"payload":{},"content":"- You will need to install the latest version with the postgres adapter (dbt-postgres).","children":[]}]},{"type":"tr","depth":4,"payload":{},"content":"","children":[{"type":"td","depth":5,"payload":{},"content":"","children":[]},{"type":"td","depth":5,"payload":{},"content":"After local installation you will have to set up the connection to PG in the <code>profiles.yml</code>, you can find the templates <a href=\"https://docs.getdbt.com/docs/core/connect-data-platform/postgres-setup\">here</a>","children":[]}]}]}]},{"type":"heading","depth":2,"payload":{"lines":[34,35]},"content":"--- EllaNotes ---","children":[{"type":"heading","depth":3,"payload":{"lines":[36,37]},"content":"Ingestion from BigQuery public dataset","children":[{"type":"list_item","depth":4,"payload":{"lines":[38,39]},"content":"BQ has","children":[{"type":"list_item","depth":5,"payload":{"lines":[39,40]},"content":"fhv data from 2015-2017","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[40,41]},"content":"green data from 2014-2023","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[41,42]},"content":"yellow data from 2011-2023","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[42,43]},"content":"project-id: <code>nyc-rides-ella</code>","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[43,44]},"content":"dataset schema: <code>trips_data_all</code>","children":[{"type":"list_item","depth":5,"payload":{"lines":[44,45]},"content":"multi region (US)","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[45,46]},"content":"table names: <code>yellow_tripdata</code>, <code>green_tripdata</code>, <code>fhv_tripdata</code>","children":[{"type":"list_item","depth":5,"payload":{"lines":[46,47]},"content":"native table","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[58,59]},"content":"Need to do cleanup with Vic's <code>hack-load-data.sql</code> from <a href=\"https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/04-analytics-engineering/taxi_rides_ny/analyses/hack-load-data.sql\">this page</a>, because the BigQuery's schema and our DTC source's schema is different. Follow DTC's schema.","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[59,60]},"content":"fhv data has to be loaded from elsewhere since BQ's public dataset do not have it, I used the <a href=\"/cohorts/2024/de-lessons/web_to_gcs.py\"><code>web_to_gcs</code></a> script with entrypoint <code>web_to_gcs('2019', 'fhv')</code> in <code>main</code> (comment out the others).","children":[]}]},{"type":"heading","depth":3,"payload":{"lines":[61,62]},"content":"Ingestion from DTC <code>nyc-tlc-data</code> repo","children":[{"type":"list_item","depth":4,"payload":{"lines":[63,64]},"content":"https://github.com/DataTalksClub/nyc-tlc-data/tree/main","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[64,65]},"content":"using tweaked <code>web_to_gcs.py</code>","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[65,66]},"content":"brute force TIMESTAMP conversion, and lots of repeats of CASE and others","children":[{"type":"list_item","depth":5,"payload":{"lines":[66,67]},"content":"BAD! not DRY-compliant","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[67,68]},"content":"disadvantages:","children":[{"type":"list_item","depth":5,"payload":{"lines":[68,69]},"content":"slow","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[69,70]},"content":"<code>.csv.gz</code> files are downloaded to local filesystem #do-not-want","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[70,71]},"content":"'.parquet' files created in local filesystem and then uploaded to GCS Buckets","children":[]}]}]},{"type":"heading","depth":3,"payload":{"lines":[72,73]},"content":"Ingestion via Mage","children":[{"type":"list_item","depth":4,"payload":{"lines":[74,75]},"content":"FIXME verify row counts, I think my looping is double loading. need to verify loops again after utilising <code>chunksize</code> in read_csv()","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[75,76]},"content":"might also be why yellow is failing","children":[{"type":"list_item","depth":5,"payload":{"lines":[76,77]},"content":"too much RAM required to process and load too much data because of the double counting","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[77,78]},"content":"CPU load reach 100% at times (of writing?) and RAM reaches almost 12GB (out of 32GB); more RAM utilised when .csv.gz files are bigger in size.","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[78,79]},"content":"green and fhv runs to completion successfully","children":[{"type":"list_item","depth":5,"payload":{"lines":[79,80]},"content":"have to make all columns of <code>str</code> as there is a lot of data with <code>nulls</code>, INTs and FLOATs fail as we're not imputing with 0s and 0.0 so the write to <code>combined_df</code> fails?","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[80,81]},"content":"yellow endlessly running after year 2019 is done and getting combined. traceback error from docker logs but no UI/UX feedback on Mage if the kernel is dead. There's been an update to <code>0.9.64</code>","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[81,82]},"content":"testing with 2 years and just 2 months reveal the concat issue with the <code>nulls</code> and my wrong looping","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[82,83]},"content":"To try again after homework submission","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[83,84]},"content":"TODO ask in Mage Slack? (about the no UI/UX indication of the traceback and endlessly circling wheel failures; will need to spend some time there to read if it has been reported)","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[84,85]},"content":"TODO can also try if polars + duckdb is not better in handling millions of rows","children":[]}]},{"type":"heading","depth":3,"payload":{"lines":[87,88]},"content":"TODO Ingestion via dlt","children":[]}]}]},{"type":"heading","depth":1,"payload":{"lines":[89,90]},"content":"Content","children":[{"type":"heading","depth":2,"payload":{"lines":[91,92]},"content":"Introduction to analytics engineering","children":[{"type":"list_item","depth":3,"payload":{"lines":[93,94]},"content":"What is analytics engineering?","children":[]},{"type":"list_item","depth":3,"payload":{"lines":[94,95]},"content":"ETL vs ELT","children":[]},{"type":"list_item","depth":3,"payload":{"lines":[95,96]},"content":"Data modeling concepts (fact and dim tables)","children":[]},{"type":"list_item","depth":3,"payload":{"lines":[96,97]},"content":"video: 4.1.1 - Analytics Engineering Basics","children":[]}]},{"type":"heading","depth":2,"payload":{"lines":[100,101]},"content":"What is dbt?","children":[{"type":"list_item","depth":3,"payload":{"lines":[102,103]},"content":"Introduction to dbt","children":[]},{"type":"list_item","depth":3,"payload":{"lines":[103,104]},"content":"video: 4.1.2 - What is dbt?","children":[]}]},{"type":"heading","depth":2,"payload":{"lines":[107,108]},"content":"--- EllaNotes ---","children":[{"type":"heading","depth":3,"payload":{"lines":[109,110]},"content":"Definitions","children":[{"type":"dl","depth":4,"payload":{"lines":[111,119]},"content":"","children":[{"type":"dt","depth":5,"payload":{"lines":[111,111]},"content":"ddl","children":[]},{"type":"dd","depth":5,"payload":{"lines":[112,115]},"content":"","children":[{"type":"paragraph","depth":6,"payload":{"lines":[112,114]},"content":"data definition language<br>\nsql statements that manage objects - tables, views","children":[]}]},{"type":"dt","depth":5,"payload":{"lines":[115,115]},"content":"dml","children":[]},{"type":"dd","depth":5,"payload":{"lines":[115,119]},"content":"","children":[{"type":"paragraph","depth":6,"payload":{"lines":[116,118]},"content":"data manipulation language<br>\nthe CRUD sql statements to SELECT, INSERT, DELETE &amp; UPDATE","children":[]}]}]},{"type":"bullet_list","depth":4,"payload":{"lines":[121,139]},"content":"","children":[{"type":"list_item","depth":5,"payload":{"lines":[121,122]},"content":"master data (like zone-lookup table) are called <code>seed files</code>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[122,123]},"content":"dbt is a transformational workflow, ie manage sql and allow for code versioning of sql, testing and documentation and deploy via CI/CD","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[123,124]},"content":"orchestrate code from dev to deployment","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[124,125]},"content":"record data sources details like schema and their lineage","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[125,126]},"content":"follows best practices in SWE workflow","children":[{"type":"list_item","depth":6,"payload":{"lines":[126,127]},"content":"modularity, DRY, testable and documented code and tests","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[127,128]},"content":"2 main ways:","children":[{"type":"list_item","depth":6,"payload":{"lines":[128,129]},"content":"cloud (web IDE/CLI, SaaS, depends on core, requires (free) Dev account on getdbt.com) and","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[129,130]},"content":"core (local, open source)","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[130,131]},"content":"because the free Dev account only allows for one project per (team) account (not Dev account?), need to do lessons and homework within this same project","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[131,132]},"content":"sign up on dbt website for a free developer account, the company name is the Team-name (limited to 1 per dev account); cannot be changed after profile created. Not explained!","children":[{"type":"list_item","depth":6,"payload":{"lines":[132,133]},"content":"Vic's is 'analytics-engineering-workshop'","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[133,134]},"content":"mine is 'a company'","children":[]}]},{"type":"list_item","depth":5,"payload":{"lines":[134,135]},"content":"TODO is it really one team account per developer account?","children":[{"type":"list_item","depth":6,"payload":{"lines":[135,136]},"content":"can create multiple accounts, test how to transfer <code>a company/taxi_rides_ny</code> to <code>de-zoomcamp/taxi_rides_ny</code>","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[136,137]},"content":"bad UX though: no feedback that the account has been created? unless I missed it in status bar or something","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[137,138]},"content":"I now have 2 de-zoomcamps, so duplications is allowed?","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[138,139]},"content":"then how to remove accounts? to ensure have clean settings","children":[]}]}]}]}]}]},{"type":"heading","depth":1,"payload":{"lines":[141,142]},"content":"Starting a dbt project","children":[{"type":"table","depth":2,"payload":{"lines":[143,149]},"content":"","children":[{"type":"thead","depth":3,"payload":{"lines":[143,144]},"content":"","children":[{"type":"th","depth":4,"payload":{"lines":[143,144]},"content":"Alternative A","children":[]},{"type":"th","depth":4,"payload":{"lines":[143,144]},"content":"Alternative B","children":[]}]},{"type":"tbody","depth":3,"payload":{"lines":[145,149]},"content":"","children":[{"type":"tr","depth":4,"payload":{},"content":"","children":[{"type":"td","depth":5,"payload":{},"content":"Using BigQuery + dbt cloud","children":[]},{"type":"td","depth":5,"payload":{},"content":"Using Postgres + dbt core (locally)","children":[]}]},{"type":"tr","depth":4,"payload":{},"content":"","children":[{"type":"td","depth":5,"payload":{},"content":"- Starting a new project with dbt init (dbt cloud and core)<br>- dbt cloud setup<br>- project.yml<br><br>","children":[]},{"type":"td","depth":5,"payload":{},"content":"- Starting a new project with dbt init (dbt cloud and core)<br>- dbt core local setup<br>- profiles.yml<br>- project.yml","children":[]}]},{"type":"tr","depth":4,"payload":{},"content":"","children":[{"type":"td","depth":5,"payload":{},"content":"video: 4.2.1 - Start Your dbt Project BigQuery and dbt Cloud (Alternative A)","children":[]},{"type":"td","depth":5,"payload":{},"content":"video: 4.2.2 - Start Your dbt Project: Postgres and dbt Core Locally (Alternative B)","children":[]}]},{"type":"tr","depth":4,"payload":{},"content":"","children":[{"type":"td","depth":5,"payload":{},"content":"<a href=\"https://www.youtube.com/watch?v=J0XCDyKiU64&amp;list=PLaNLNpjZpzwgneiI-Gl8df8GCsPYp_6Bs&amp;index=4\"><img src=\"https://markdown-videos-api.jorgenkh.no/youtube/iMxh6s_wL4Q\" alt=\"\"></a>","children":[]},{"type":"td","depth":5,"payload":{},"content":"<a href=\"https://youtu.be/1HmL63e-vRs&amp;list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&amp;index=43\"><img src=\"https://markdown-videos-api.jorgenkh.no/youtube/1HmL63e-vRs\" alt=\"\"></a>","children":[]}]}]}]},{"type":"heading","depth":2,"payload":{"lines":[150,151]},"content":"--- EllaNotes ---","children":[{"type":"ordered_list","depth":3,"payload":{"lines":[154,160],"startIndex":1},"content":"","children":[{"type":"list_item","depth":4,"payload":{"lines":[154,155],"index":1},"content":"1. <code>model</code> in dbt refers to SQL queries in dbt code yml format","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[155,156],"index":2},"content":"2. sign up on dbt website for a free developer account, the company name is the Team-name (limited to 1 per dev account); cannot be changed after profile created. Not explained!","children":[{"type":"list_item","depth":5,"payload":{"lines":[156,157]},"content":"Vic's is 'analytics-engineering-workshop'","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[157,158]},"content":"mine is 'a company'","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[158,159],"index":3},"content":"3. setup your project like so","children":[]}]},{"type":"ordered_list","depth":3,"payload":{"lines":[163,166],"startIndex":4},"content":"","children":[{"type":"list_item","depth":4,"payload":{"lines":[163,164],"index":4},"content":"4. assuming we're in the parent folder to <code>taxi_rides_ny</code> path, once we create a branch, the <code>Initialize dbt poject</code> green button","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[164,165],"index":5},"content":"5. once we init, the contents of the dbt project is generated","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[165,166],"index":6},"content":"6. edit <code>dbt_project.yml</code> with our BQ <code>project-name</code> in the <code>name</code> field","children":[]}]},{"type":"fence","depth":3,"content":"<pre><code class=\"language-yaml\"><span class=\"hljs-attr\">name:</span> <span class=\"hljs-string\">&#x27;taxi_rides_ny&#x27;</span>\n<span class=\"hljs-attr\">version:</span> <span class=\"hljs-string\">&#x27;1.0.0&#x27;</span>\n<span class=\"hljs-attr\">config-version:</span> <span class=\"hljs-number\">2</span>\n\n\n</code></pre>\n","children":[],"payload":{"lines":[166,173]}}]},{"type":"heading","depth":2,"payload":{"lines":[176,177]},"content":"dbt models","children":[{"type":"bullet_list","depth":3,"payload":{"lines":[178,186]},"content":"","children":[{"type":"list_item","depth":4,"payload":{"lines":[178,179]},"content":"Anatomy of a dbt model: written code vs compiled Sources","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[179,180]},"content":"Materialisations: table, view, incremental, ephemeral","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[180,181]},"content":"Seeds, sources and ref","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[181,182]},"content":"Jinja and Macros","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[182,183]},"content":"Packages","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[183,184]},"content":"Variables","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[184,185]},"content":"video: 4.3.1 - Build the First dbt Models","children":[]}]},{"type":"blockquote","depth":3,"payload":{"lines":[188,190]},"content":"","children":[{"type":"paragraph","depth":4,"payload":{"lines":[188,190]},"content":"[!NOTE]<br>\n<em>This video is shown entirely on dbt cloud IDE but the same steps can be followed locally on the IDE of your choice</em>","children":[]}]},{"type":"blockquote","depth":3,"payload":{"lines":[191,195]},"content":"","children":[{"type":"paragraph","depth":4,"payload":{"lines":[191,193]},"content":"[!TIP]<br>\nIf you recieve an error stating &quot;Permission denied while globbing file pattern.&quot; when attempting to run <code>fact_trips.sql</code> this video may be helpful in resolving the issue","children":[]},{"type":"paragraph","depth":4,"payload":{"lines":[194,195]},"content":"<a href=\"https://youtu.be/kL3ZVNL9Y4A&amp;list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&amp;index=34\"><img src=\"https://markdown-videos-api.jorgenkh.no/youtube/kL3ZVNL9Y4A\" alt=\"\"></a>","children":[]}]}]},{"type":"heading","depth":2,"payload":{"lines":[196,197]},"content":"--- EllaNotes ---","children":[{"type":"ordered_list","depth":3,"payload":{"lines":[199,218],"startIndex":1},"content":"","children":[{"type":"list_item","depth":4,"payload":{"lines":[199,200],"index":1},"content":"1. master data aka seeds aka lookups ie our zones data","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[200,201],"index":2},"content":"2. fact tables (), dimensional tables (sources: trip data)","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[201,202],"index":3},"content":"3. sql scripts are called <code>models</code> in dbt","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[202,203],"index":4},"content":"4. dbt generates the ddl and dml for us when we <code>compile</code> our model code with <code>dbt build</code>, and <code>dbt run</code> then uses this compiled code","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[203,204],"index":5},"content":"5. materialization types: ephemeral, view, table, incremental (drop &amp; re-create, or insert new data in same table)","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[204,205],"index":6},"content":"6. dependencies coded into the model and follows from dev to staging to production, and also in version control","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[205,207],"index":7},"content":"7. to start our dbt project, first create a <code>staging</code> folder under <code>model</code> folder<br>\n<img src=\"../images/dbt-start-define-source.png\" alt=\"\">","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[207,209],"index":8},"content":"8. and then create <code>schema.yml</code> in this folder<br>\n<img src=\"../images/dbt-start-schema-file.png\" alt=\"\">","children":[{"type":"list_item","depth":5,"payload":{"lines":[209,210]},"content":"change the <code>database</code> entry to the <code>dataset</code> value from your BigQuery instance and mine is <code>nyc-rides-ella</code>, which for me I've set it to be the same as my <code>project-id</code> (maybe I shouldn't have done this? well hindsight 20/20 and all that)","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[210,211]},"content":"input <code>tables</code> names of <code>green_tripdata</code> and <code>yellow_tripdata</code>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[211,212]},"content":"once you typed in the tables names, dbt would prompt you to <code>generate model</code>, click on this and new tab pops open with model <code>stg_staging__green_tripdata.sql</code> in another <code>staging</code> subfolder","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[212,213],"index":9},"content":"9. <code>Save</code> this yml file and move it one level up, we don't want it nested <code>/model/staging/staging</code> but just <code>model/staging</code>","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[213,214],"index":10},"content":"10. also remove the folder after you've moved the yml file","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[214,215],"index":11},"content":"11. and finally rename the yml file to remove that extra <code>staging</code> so final filename is <code>taxi_rides_ny/models/staging/stg_green_tripdata.sql</code>","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[215,216],"index":12},"content":"12. test <code>dbt build</code> in the console CLI and it should fail as it is starting from the <code>example</code> models subfolder, and due to this failed step, all the subsequent steps are skipped because these are dependencies","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[216,217],"index":13},"content":"13. we're going to remove these <code>example</code> models and tests, simply by removing the folder under <code>models</code> and continue","children":[]}]},{"type":"ordered_list","depth":3,"payload":{"lines":[222,246],"startIndex":1},"content":"","children":[{"type":"list_item","depth":4,"payload":{"lines":[222,223],"index":1},"content":"1. <code>macros</code>: uses templating language <code>jinja</code>","children":[{"type":"list_item","depth":5,"payload":{"lines":[223,224]},"content":"is applicable project-wide","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[224,225]},"content":"akin to utilities/helper functions &amp; .env/config code in Python","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[225,226]},"content":"it's common code that can be used repeatedly in all our models throughout the project","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[226,228]},"content":"create <code>get_payment_type_description.sql</code> under the <code>macros</code> folder<br>\n<img src=\"../images/dbt-add-macros-get-payment-type-desc.png\" alt=\"\">","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[228,229]},"content":"copy contents from <a href=\"../04-analytics-engineering/taxi_rides_ny/macros/get_payment_type_description.sql\">dtc repo</a>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[229,231]},"content":"add this <code>{{ get_payment_type_description('payment_type') }}</code><br>\nin line#30 in <code>/models/staging/stg_green_tripdata.sql as payment_type_descripted</code>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[231,232]},"content":"just like Python's UDF, macros can also be packaged and reused in other projects","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[232,233]},"content":"and similarly just like <a href=\"https://pypi.org\"><em>PyPi.org</em></a> hosting packages others have made, dbt also has a <em><a href=\"https://hub.getdbt.com/\">dbt package hub</a></em> and we declare the import statements in a <code>packages.yml</code> file","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[233,234]},"content":"the syntax is similar to how we add images in a <code>docker-compose.yml</code> file for Docker containers","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[234,236],"index":2},"content":"2. create <code>packages.yml</code> file in your root dbt project folder, ie in the same path as the <code>dbt_project.yml</code> file<br>\n<img src=\"../images/dbt-add-packages.png\" alt=\"\">","children":[{"type":"bullet_list","depth":5,"payload":{"lines":[236,242]},"content":"","children":[{"type":"list_item","depth":6,"payload":{"lines":[236,237]},"content":"once file is saved, it would trigger the install and you'll see in the command line that it's doing just that and then building","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[237,238]},"content":"if it does not gets triggered, you can manually kick off the process by doing a <code>dpt deps</code> in the CLI","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[238,239]},"content":"you'll see the packages imported once it is done and new <code>dbt_packages</code> folder appear in your File Explorer tree","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[239,240]},"content":"find the usage guide in the docs or gh repo","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[240,241]},"content":"for our case, we want to declare a new primary key <code>tripid</code> that combines these 2 columns <code>vendorid</code> + <code>lpep_pickup_datetime</code>, because one cab can only have a unique trip at a particular timestamp","children":[]},{"type":"list_item","depth":6,"payload":{"lines":[241,242]},"content":"at the beginning of our SELECT statement in the <code>stg_green_tripdata.sql</code> file, add this:","children":[]}]},{"type":"bullet_list","depth":5,"payload":{"lines":[245,246]},"content":"","children":[{"type":"list_item","depth":6,"payload":{"lines":[245,246]},"content":"we should be able to verify the output in our <code>nyc-rides-ella.dbt_ellacharmed</code> dataset in BigQuery","children":[]}]}]}]},{"type":"blockquote","depth":3,"payload":{"lines":[246,248]},"content":"","children":[{"type":"paragraph","depth":4,"payload":{"lines":[246,248]},"content":"[!TIP]<br>\nif you get <code>dbt build failed</code> check for commas in the 2 lines we added","children":[]}]},{"type":"ordered_list","depth":3,"payload":{"lines":[251,259],"startIndex":1},"content":"","children":[{"type":"list_item","depth":4,"payload":{"lines":[251,252],"index":1},"content":"1. after the above thorough walkthrough, we can now just copy+paste the model code from DTC repository and learn what else Vic has added for the final output","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[252,253],"index":2},"content":"2. we can explicitly use the <code>__config</code> shortcut to declare the config to materialize all this as a <code>view</code>, but it is the default anyway. It could be best practice if you want to be very clear of which model would materialize a <code>view</code> or a <code>table</code> or something else","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[253,254],"index":3},"content":"3. the model code now checks for","children":[{"type":"list_item","depth":5,"payload":{"lines":[254,255]},"content":"duplicated rows, we only bring in row data that has <code>rn</code>=1 ie 1 count of each row, no duplication","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[255,256]},"content":"exclude rows with null <code>vendorid</code>","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[256,257]},"content":"lots of CASTing of data types so the schema is consistent with yellow table","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[257,258]},"content":"renaming column names","children":[]}]}]},{"type":"ordered_list","depth":3,"payload":{"lines":[261,279],"startIndex":1},"content":"","children":[{"type":"list_item","depth":4,"payload":{"lines":[261,262],"index":1},"content":"1. <code>variables</code> can also be defined at the project level in dbt","children":[{"type":"list_item","depth":5,"payload":{"lines":[262,263]},"content":"we used this var <code>dbt build --vars '{'is_test_run': 'true'}'</code> in our code for this project to <code>limit 100</code> when we're just testing our code builds, by declaring ``","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[263,264]},"content":"so we're performing faster and cheaper queries in BQ while in dev mode","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[264,266],"index":2},"content":"2. at this time, our lineage graph looks like this<br>\n<img src=\"../images/dbt-lineage-after-stg.png\" alt=\"\">","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[266,267],"index":3},"content":"3. now, we're going to add our zones data. Create a new folder under <code>/models</code>, call it <code>core</code>","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[267,269],"index":4},"content":"4. in this folder, create a new model called <code>dim_zones.sql</code> so our zones master data lives in the path <code>/models/core/dim_zones.sql</code><br>\n<img src=\"../images/dbt-add-core-dim-zones.png\" alt=\"\">","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[269,270],"index":5},"content":"5. copy+paste the contents of the lookup table in the raw data file from <a href=\"04-analytics-engineering/taxi_rides_ny/seeds/taxi_zone_lookup.csv\">DTC repo taxi_zone_lookup.csv</a> and save it into the path <code>/taxi_rides_ny/seeds/taxi_zone_lookup.csv</code>","children":[{"type":"list_item","depth":5,"payload":{"lines":[270,271]},"content":"perform a <code>Build</code> while in the csv tab, and you should be able to refresh your dataset in BQ and the seed lookup file would appear there","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[271,272]},"content":"need to edit and add exclusion <code>!seeds/taxi_zone_lookup.csv</code> to the <code>.gitignore</code> file so this .csv file would be tracked by version control, else the Nightly scheduled runs would fail","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[272,274],"index":6},"content":"6. we next create the <code>fact_trips.sql</code> under <code>core</code> folder, contents is at <a href=\"https://github.com/DataTalksClub/data-engineering-zoomcamp/blob/main/04-analytics-engineering/taxi_rides_ny/models/core/fact_trips.sql\">DTC repo fact_trips.sql</a><br>\n<img src=\"../images/dbt-add-core-fact-trips.png\" alt=\"\">","children":[{"type":"list_item","depth":5,"payload":{"lines":[274,276]},"content":"at this point of time, our lineage graph now looks like this<br>\n<img src=\"../images/dbt-lineage-after-fct.png\" alt=\"\">","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[276,277]},"content":"we also exclude any records from green and yellow trips if the zones are <code>Unknown</code>","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[277,278],"index":7},"content":"7. due to <code>ehail_fee</code> issues below, dropped all tables (previously uploaded by <code>web_to_gcs.py</code> script) and regenerate bucket storage using Vic's <a href=\"../04-analytics-engineering/taxi_rides_ny/analyses/hack-load-data.sql\">hack-load-data.sql</a>. <code>ehail_fee</code> does not occur with this method","children":[]}]},{"type":"ordered_list","depth":3,"payload":{"lines":[284,285],"startIndex":8},"content":"","children":[{"type":"list_item","depth":4,"payload":{"lines":[284,285],"index":8},"content":"8. make sure to do a final <code>dbt build</code> with below flags for homework, because otherwise the data is limited to first 100 records","children":[]}]},{"type":"fence","depth":3,"content":"<pre><code class=\"language-sql\">dbt build <span class=\"hljs-comment\">--vars &#x27;{&#x27;is_test_run&#x27;: &#x27;false&#x27;}&#x27;</span>\n</code></pre>\n","children":[],"payload":{"lines":[285,288]}}]},{"type":"heading","depth":2,"payload":{"lines":[291,292]},"content":"Testing and documenting dbt models","children":[{"type":"bullet_list","depth":3,"payload":{"lines":[293,297]},"content":"","children":[{"type":"list_item","depth":4,"payload":{"lines":[293,294]},"content":"Tests","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[294,295]},"content":"Documentation","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[295,296]},"content":"video: 4.3.2 - Testing and Documenting the Project","children":[]}]},{"type":"blockquote","depth":3,"payload":{"lines":[300,302]},"content":"","children":[{"type":"paragraph","depth":4,"payload":{"lines":[300,302]},"content":"[!NOTE]<br>\nThis video is shown entirely on dbt cloud IDE but the same steps can be followed locally on the IDE of your choice*","children":[]}]}]},{"type":"heading","depth":2,"payload":{"lines":[303,304]},"content":"--- EllaNotes ---","children":[{"type":"ordered_list","depth":3,"payload":{"lines":[305,324],"startIndex":1},"content":"","children":[{"type":"list_item","depth":4,"payload":{"lines":[305,306],"index":1},"content":"1. video: 4.3.2 - Testing and Documenting the Project","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[306,307],"index":2},"content":"2. basic tests includes","children":[{"type":"list_item","depth":5,"payload":{"lines":[307,308]},"content":"unique values","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[308,309]},"content":"not null values","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[309,310]},"content":"accepted values","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[310,311]},"content":"foreign key to other tables","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[311,313],"index":3},"content":"3. create <code>dm_monthly_zone_revenue.sql</code> from <a href=\"../04-analytics-engineering/taxi_rides_ny/models/core/dm_monthly_zone_revenue.sql\">dtc repo</a> under <code>/models/core/</code><br>\n<img src=\"../images/dbt-test-dim-monthly.png\" alt=\"\">","children":[{"type":"list_item","depth":5,"payload":{"lines":[313,314]},"content":"the <code>dbt.date_trunc</code> is referred to 'cross database macros'","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[314,315],"index":4},"content":"4. another package we had used unconsciously is the <code>Generate model</code> command when we created our tables","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[315,316],"index":5},"content":"5. we're using the <a href=\"https://github.com/dbt-labs/dbt-codegen/tree/0.12.1/?tab=readme-ov-file#generate_model_yaml-source\">generate_model_yaml-source</a> code generator.","children":[{"type":"list_item","depth":5,"payload":{"lines":[316,317]},"content":"in order for the generator to generate documentation yaml code, the schema.yml must contain the column names, description and tests being done","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[317,318]},"content":"paste this block into a new file (it's temporary), we want the code it generates, so this code need not be saved","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[318,319]},"content":"what this does is to generate the boilerplate code to have docstrings and our models' data types","children":[]},{"type":"list_item","depth":5,"payload":{"lines":[319,320]},"content":"we can then add some test blocks to ensure our code meet the standards of the basics test above","children":[]}]},{"type":"list_item","depth":4,"payload":{"lines":[320,321],"index":6},"content":"6. can also look at <code>dbt_expectations</code> package for more tests","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[321,322],"index":7},"content":"7. can generate docs to be hosted on the project website to show docstrings for the project, tables or columns","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[322,323],"index":8},"content":"8. create a <code>schema.yml</code> for tables under <code>staging</code> and <code>core</code> by <code>compile selection</code> on below code block, select and compile separately","children":[]}]},{"type":"fence","depth":3,"content":"<pre><code class=\"language-sql\">{% set models_to_generate = codegen.get_models(directory=&#x27;staging&#x27;, prefix=&#x27;stg&#x27;) %}\n{{ codegen.generate_model_yaml(\n    model_names = models_to_generate) }}\n\n{% set models_to_generate = codegen.get_models(directory=&#x27;core&#x27;) %}\n{{ codegen.generate_model_yaml(\n    model_names = models_to_generate) }}\n</code></pre>\n","children":[],"payload":{"lines":[324,333]}},{"type":"ordered_list","depth":3,"payload":{"lines":[333,335],"startIndex":9},"content":"","children":[{"type":"list_item","depth":4,"payload":{"lines":[333,334],"index":9},"content":"9. then in cloud CLI, run <code>dbt docs generate</code>","children":[{"type":"list_item","depth":5,"payload":{"lines":[334,335]},"content":"if locally run <code>dbt docs serve</code>","children":[]}]}]}]}]},{"type":"heading","depth":1,"payload":{"lines":[338,339]},"content":"Deployment","children":[{"type":"table","depth":2,"payload":{"lines":[340,346]},"content":"","children":[{"type":"thead","depth":3,"payload":{"lines":[340,341]},"content":"","children":[{"type":"th","depth":4,"payload":{"lines":[340,341]},"content":"Alternative A","children":[]},{"type":"th","depth":4,"payload":{"lines":[340,341]},"content":"Alternative B","children":[]}]},{"type":"tbody","depth":3,"payload":{"lines":[342,346]},"content":"","children":[{"type":"tr","depth":4,"payload":{},"content":"","children":[{"type":"td","depth":5,"payload":{},"content":"Using BigQuery + dbt cloud","children":[]},{"type":"td","depth":5,"payload":{},"content":"Using Postgres + dbt core (locally)","children":[]}]},{"type":"tr","depth":4,"payload":{},"content":"","children":[{"type":"td","depth":5,"payload":{},"content":"- Deployment: development environment vs production<br>- dbt cloud: scheduler, sources and hosted documentation","children":[]},{"type":"td","depth":5,"payload":{},"content":"- Deployment: development environment vs production<br>-  dbt cloud: scheduler, sources and hosted documentation","children":[]}]},{"type":"tr","depth":4,"payload":{},"content":"","children":[{"type":"td","depth":5,"payload":{},"content":"4.4.1 - Deployment Using dbt Cloud (Alternative A)","children":[]},{"type":"td","depth":5,"payload":{},"content":"4.4.2 - Deployment Using dbt Locally (Alternative B)","children":[]}]},{"type":"tr","depth":4,"payload":{},"content":"","children":[{"type":"td","depth":5,"payload":{},"content":"<a href=\"https://www.youtube.com/watch?v=V2m5C0n8Gro&amp;list=PLaNLNpjZpzwgneiI-Gl8df8GCsPYp_6Bs&amp;index=6\"><img src=\"https://markdown-videos-api.jorgenkh.no/youtube/rjf6yZNGX8I\" alt=\"\"></a>","children":[]},{"type":"td","depth":5,"payload":{},"content":"<a href=\"https://youtu.be/Cs9Od1pcrzM&amp;list=PL3MmuxUbc_hJed7dXYoJw8DoCuVHhGEQb&amp;index=47\"><img src=\"https://markdown-videos-api.jorgenkh.no/youtube/Cs9Od1pcrzM\" alt=\"\"></a>","children":[]}]}]}]},{"type":"heading","depth":2,"payload":{"lines":[348,349]},"content":"--- EllaNotes ---","children":[{"type":"ordered_list","depth":3,"payload":{"lines":[350,355],"startIndex":1},"content":"","children":[{"type":"list_item","depth":4,"payload":{"lines":[350,351],"index":1},"content":"1. set <code>PROD</code> to look at <code>ella2024</code> branch instead of default <code>main</code>","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[351,352],"index":2},"content":"2. initial issue was the <code>seeds/*.csv</code> is in .gitignore and the <code>Nightly</code> jobs won't run to a <code>Success</code> status","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[352,353],"index":3},"content":"3. edited <code>.gitignore</code> to add exclusion","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[353,354],"index":4},"content":"4. solution from <a href=\"https://datatalks-club.slack.com/archives/C01FABYF2RG/p1708002206775409\">drux's slack thread</a>","children":[]}]},{"type":"blockquote","depth":3,"payload":{"lines":[355,367]},"content":"","children":[]}]}]},{"type":"heading","depth":1,"payload":{"lines":[355,357]},"content":"[!WARNING]","children":[]},{"type":"heading","depth":1,"payload":{"lines":[357,359]},"content":"Invoke dbt Command","children":[{"type":"list_item","depth":2,"payload":{"lines":[368,369],"index":1},"content":"1. create a PR from <code>module-04</code> (subsequently <code>dbt-deploy</code>) to merge to <code>ella2024</code>, Nightly job now picks up the commitId <code>bb7d29e</code> but hit the same error. turns out the exclusion is still in <code>module-04</code> and not <code>dbt-deploy</code>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[369,371],"index":2},"content":"2. <code>CI checks</code> demo for CI jobs is not possible? Also see <a href=\"https://datatalks-club.slack.com/archives/C01FABYF2RG/p1707972535660619\">slack chat on Trial acct and CI jobs</a><br>\n<img src=\"../images/dbt-trial-ci-jobs-restricted.png\" alt=\"\">","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[371,374],"index":3},"content":"3. Solution is to unlink from the current <code>Git Clone</code> and re-link using <code>Github</code><br>\n<img src=\"../images/git-clone-vs-github.png\" alt=\"\"><br>\nTODO check back after the <code>Team</code> Trial period expires (sometime during module-05), if we can still perform <code>CI checks</code> job under Free <code>Developer</code> account.","children":[]}]},{"type":"heading","depth":1,"payload":{"lines":[376,377]},"content":"Visualising the transformed data","children":[{"type":"heading","depth":2,"payload":{"lines":[386,387]},"content":"--- EllaNotes ---","children":[{"type":"list_item","depth":3,"payload":{"lines":[388,389]},"content":"Google data studio is now renamed to <a href=\"https://lookerstudio.google.com/\">Looker Studio</a>; works like the ususal Google shareable apps such as G-Docs and G-Sheets","children":[]},{"type":"list_item","depth":3,"payload":{"lines":[389,390]},"content":"Metabase Docker image <code>docker run -d -p 3000:3000 --name metabase metabase/metabase</code>","children":[]},{"type":"list_item","depth":3,"payload":{"lines":[390,391]},"content":"TODO test with Power BI to BQ","children":[]},{"type":"list_item","depth":3,"payload":{"lines":[391,392]},"content":"TODO test with Tableau to BQ","children":[]},{"type":"list_item","depth":3,"payload":{"lines":[392,393]},"content":"free and open-source alternatives to Power BI and Tableau that can connect to private BigQuery datasets according to BingCoPilot","children":[{"type":"list_item","depth":4,"payload":{"lines":[393,394]},"content":"Apache Superset","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[394,395]},"content":"PopSQL","children":[]},{"type":"list_item","depth":4,"payload":{"lines":[395,396]},"content":"LinceBi","children":[]}]},{"type":"list_item","depth":3,"payload":{"lines":[396,397]},"content":"the same question to Gemini, only adds one more to the list above","children":[{"type":"list_item","depth":4,"payload":{"lines":[397,398]},"content":"Redash","children":[]}]}]}]},{"type":"heading","depth":1,"payload":{"lines":[399,400]},"content":"Advanced concepts","children":[{"type":"list_item","depth":2,"payload":{"lines":[401,402]},"content":"<a href=\"https://docs.getdbt.com/docs/building-a-dbt-project/building-models/configuring-incremental-models\">Make a model Incremental</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[402,403]},"content":"<a href=\"https://docs.getdbt.com/reference/resource-configs/tags\">Use of tags</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[403,404]},"content":"<a href=\"https://docs.getdbt.com/docs/building-a-dbt-project/hooks-operations\">Hooks</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[404,405]},"content":"<a href=\"https://docs.getdbt.com/docs/building-a-dbt-project/analyses\">Analysis</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[405,406]},"content":"<a href=\"https://docs.getdbt.com/docs/building-a-dbt-project/snapshots\">Snapshots</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[406,407]},"content":"<a href=\"https://docs.getdbt.com/docs/building-a-dbt-project/exposures\">Exposure</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[407,408]},"content":"<a href=\"https://docs.getdbt.com/docs/building-a-dbt-project/metrics\">Metrics</a>","children":[]}]},{"type":"heading","depth":1,"payload":{"lines":[410,411]},"content":"Community notes","children":[{"type":"list_item","depth":2,"payload":{"lines":[414,415]},"content":"<a href=\"https://github.com/ziritrion/dataeng-zoomcamp/blob/main/notes/4_analytics.md\">Notes by Alvaro Navas</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[415,416]},"content":"<a href=\"https://learningdataengineering540969211.wordpress.com/2022/02/17/week-4-setting-up-dbt-cloud-with-bigquery/\">Sandy's DE learning blog</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[416,417]},"content":"<a href=\"https://github.com/padilha/de-zoomcamp/tree/master/week4\">Notes by Victor Padilha</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[417,418]},"content":"<a href=\"https://www.n4gash.com/2023/data-engineering-zoomcamp-semana-4/\">Marcos Torregrosa's blog (spanish)</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[418,419]},"content":"<a href=\"https://github.com/froukje/de-zoomcamp/blob/main/week_4_analytics_engineering/notes/notes_week_04.md\">Notes by froukje</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[419,420]},"content":"<a href=\"https://github.com/boisalai/de-zoomcamp-2023/blob/main/week4.md\">Notes by Alain Boisvert</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[420,421]},"content":"<a href=\"https://medium.com/@verazabeida/zoomcamp-week-5-5b6a9d53a3a0\">Setting up Prefect with dbt by Vera</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[421,422]},"content":"<a href=\"https://xiahe-bleinagel.com/2023/02/week-4-data-engineering-zoomcamp-notes-analytics-engineering-and-dbt/\">Blog by Xia He-Bleinagel</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[422,423]},"content":"<a href=\"https://medium.com/@fagbuyit/setting-up-your-dbt-cloud-dej-9-d18e5b7c96ba\">Setting up DBT with BigQuery by Tofag</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[423,424]},"content":"<a href=\"https://medium.com/@oktavianidewi/de-zoomcamp-2023-learning-week-4-analytics-engineering-with-dbt-53f781803d3e\">Blog post by Dewi Oktaviani</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[424,425]},"content":"<a href=\"https://binchentso.notion.site/Data-Talks-Club-Data-Engineering-Zoomcamp-8699af8e7ff94ec49e6f9bdec8eb69fd\">Notes from Vincenzo Galante</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[425,426]},"content":"<a href=\"https://github.com/Balajirvp/DE-Zoomcamp/blob/main/Week%204/Data%20Engineering%20Zoomcamp%20Week%204.ipynb\">Notes from Balaji</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[426,427]},"content":"<a href=\"https://github.com/inner-outer-space/de-zoomcamp-2024/blob/main/4-analytics-engineering/readme.md\">Notes by Linda</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[427,428]},"content":"<a href=\"https://drive.google.com/drive/folders/1V2sHWOotPEMQTdMT4IMki1fbMPTn3jOP?usp=drive\">2024 - Videos transcript week4</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[428,429]},"content":"resources shared by <a href=\"https://datatalks-club.slack.com/archives/C01FABYF2RG/p1707217006946489\">Luis in Slack</a>","children":[{"type":"list_item","depth":3,"payload":{"lines":[429,430]},"content":"<a href=\"https://medium.com/@lgsoliveira/3-reasons-why-working-with-data-build-tool-dbt-is-not-just-doing-sql-5b8d9c40a591\">3 Reasons Why Working With Data Build Tool (dbt) Is Not Just Doing SQL</a>","children":[]},{"type":"list_item","depth":3,"payload":{"lines":[430,431]},"content":"<a href=\"https://medium.com/gitconnected/5-strong-reasons-why-data-build-tool-dbt-got-so-much-hype-9030dda48b74\">5 Strong Reasons Why Data Build Tool (dbt) Got So Much Hype</a>","children":[]},{"type":"list_item","depth":3,"payload":{"lines":[431,432]},"content":"<a href=\"https://medium.com/gitconnected/analytics-engineer-roadmap-2023-with-free-resources-873195184ebd?sk=312e752dc1bbbbd4c5f5ba05b142b7d8\">Analytics Engineer Roadmap 2023 With Free Resources</a>","children":[]}]},{"type":"list_item","depth":2,"payload":{"lines":[432,433]},"content":"Add your notes here (above this line)","children":[]}]},{"type":"heading","depth":1,"payload":{"lines":[435,436]},"content":"Useful links","children":[{"type":"list_item","depth":2,"payload":{"lines":[437,438]},"content":"<a href=\"https://docs.google.com/presentation/d/1xSll_jv0T8JF4rYZvLHfkJXYqUjPtThA/edit?usp=sharing&amp;ouid=114544032874539580154&amp;rtpof=true&amp;sd=true\">Slides used in the videos</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[438,439]},"content":"<a href=\"https://www.metabase.com/learn/visualization/\">Visualizing data with Metabase course</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[439,440]},"content":"<a href=\"https://courses.getdbt.com/collections\">dbt free courses</a>","children":[]},{"type":"list_item","depth":2,"payload":{"lines":[440,441]},"content":"https://startlearningcode.com/2020/01/08/visual-studio-code-sqltools-extension/","children":[]}]}]},{})</script>
</body>
</html>
